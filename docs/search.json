[
  {
    "objectID": "statecons.html",
    "href": "statecons.html",
    "title": "State_constitutions",
    "section": "",
    "text": "Connecticut: https://www.cga.ct.gov/asp/Content/constitutions/1818Constitution.htm (Basil-Anne)\nDelaware: https://avalon.law.yale.edu/18th_century/de02.asp (Basil-Anne)\nGeorgia: https://avalon.law.yale.edu/18th_century/ga02.asp (Katie)\nMaryland: https://avalon.law.yale.edu/17th_century/ma02.asp (Katie)\nMassachusetts: http://www.nhinet.org/ccs/docs/ma-1780.htm (Basil-Anne)\nNew Hampshire: https://avalon.law.yale.edu/18th_century/nh09.asp (Katie)\nNew Jersey: https://avalon.law.yale.edu/18th_century/nj15.asp (Katie)\nNew York: https://avalon.law.yale.edu/18th_century/ny01.asp (Cassie)\nNorth Carolina: https://avalon.law.yale.edu/18th_century/nc07.asp (Cassie)\nPennsylvania: https://avalon.law.yale.edu/18th_century/pa08.asp (Cassie)\nRhode Island: https://www.wordservice.org/State%20Constitutions/usa1031.htm (Basil-Anne)\nSouth Carolina: https://avalon.law.yale.edu/18th_century/sc02.asp (Cassie)\nVirginia: https://www.wordservice.org/State%20Constitutions/usa1025.htm (Basil-Anne)"
  },
  {
    "objectID": "statecons.html#list-of-states",
    "href": "statecons.html#list-of-states",
    "title": "State_constitutions",
    "section": "",
    "text": "Connecticut: https://www.cga.ct.gov/asp/Content/constitutions/1818Constitution.htm (Basil-Anne)\nDelaware: https://avalon.law.yale.edu/18th_century/de02.asp (Basil-Anne)\nGeorgia: https://avalon.law.yale.edu/18th_century/ga02.asp (Katie)\nMaryland: https://avalon.law.yale.edu/17th_century/ma02.asp (Katie)\nMassachusetts: http://www.nhinet.org/ccs/docs/ma-1780.htm (Basil-Anne)\nNew Hampshire: https://avalon.law.yale.edu/18th_century/nh09.asp (Katie)\nNew Jersey: https://avalon.law.yale.edu/18th_century/nj15.asp (Katie)\nNew York: https://avalon.law.yale.edu/18th_century/ny01.asp (Cassie)\nNorth Carolina: https://avalon.law.yale.edu/18th_century/nc07.asp (Cassie)\nPennsylvania: https://avalon.law.yale.edu/18th_century/pa08.asp (Cassie)\nRhode Island: https://www.wordservice.org/State%20Constitutions/usa1031.htm (Basil-Anne)\nSouth Carolina: https://avalon.law.yale.edu/18th_century/sc02.asp (Cassie)\nVirginia: https://www.wordservice.org/State%20Constitutions/usa1025.htm (Basil-Anne)"
  },
  {
    "objectID": "statecons.html#connecticut",
    "href": "statecons.html#connecticut",
    "title": "State_constitutions",
    "section": "Connecticut",
    "text": "Connecticut\n\nlibrary(rvest)\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidytext)\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.2.3\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\nlibrary(forcats)\n\nct_url &lt;- \"https://www.cga.ct.gov/asp/Content/constitutions/1818Constitution.htm\"\nct_html &lt;- read_html(ct_url)\n\nct_text &lt;- html_text(ct_html)\n\nct_con &lt;- data.frame(word = unlist(strsplit(ct_text, \"\\\\s+\"))) %&gt;%\n\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) %&gt;%\n  filter(!word==\"\")\n\nrows_to_exclude_ct &lt;- c(1:7, 223:298, 6012:12230)\n\nct_con_tidy &lt;- ct_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_ct))\n\nct_con_join &lt;- ct_con_tidy %&gt;%\n  mutate(state = rep(\"Connecticut\"))\n\n\nct_word_count &lt;- ct_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word)\n\ndata(\"stop_words\")\nct_con_tidy_nostop &lt;- ct_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nct_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) \n\n           word   n\n1           sec 100\n2           art  94\n3      assembly  44\n4     governour  36\n5           law  35\n6         house  25\n7        office  25\n8    amendments  23\n9       altered  22\n10        votes  21\n11            4  20\n12     electors  20\n13       manner  20\n14 constitution  19\n15       person  19\n16         time  19\n17            3  18\n18    secretary  18\n19            6  17\n20            2  15\n21         town  15"
  },
  {
    "objectID": "statecons.html#delaware",
    "href": "statecons.html#delaware",
    "title": "State_constitutions",
    "section": "Delaware",
    "text": "Delaware\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nde_url &lt;- \"https://avalon.law.yale.edu/18th_century/de02.asp\"\nde_html &lt;- read_html(de_url)\n\nde_text &lt;- html_text(de_html)\n\nde_con &lt;- data.frame(word = unlist(strsplit(de_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  \n\nrows_to_exclude &lt;- c(1:54, 3721:3796)\n\nde_con_tidy &lt;- de_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude))\n\nde_con_join &lt;- de_con_tidy %&gt;%\n  mutate(state = rep(\"Delaware\"))"
  },
  {
    "objectID": "statecons.html#georgia",
    "href": "statecons.html#georgia",
    "title": "State_constitutions",
    "section": "Georgia",
    "text": "Georgia\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nga_url &lt;- \"https://avalon.law.yale.edu/18th_century/ga02.asp\"\nga_html &lt;- read_html(ga_url)\n\nga_text &lt;- html_text(ga_html)\n\nga_con &lt;- data.frame(word = unlist(strsplit(ga_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  \n\nrows_to_exclude_ga &lt;- c(1:56, 4422:4652)\n\nga_con_tidy &lt;- ga_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_ga))\n\nga_con_join &lt;- ga_con_tidy %&gt;%\n  mutate(state = rep(\"Georgia\"))"
  },
  {
    "objectID": "statecons.html#maryland",
    "href": "statecons.html#maryland",
    "title": "State_constitutions",
    "section": "Maryland",
    "text": "Maryland\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nmd_url &lt;- \"https://avalon.law.yale.edu/17th_century/ma02.asp\"\nmd_html &lt;- read_html(md_url)\n\nmd_text &lt;- html_text(md_html)\n\nmd_con &lt;- data.frame(word = unlist(strsplit(md_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  \n\nrows_to_exclude_md &lt;- c(1:94, 2623:2669, 8854:9084)\n\nmd_con_tidy &lt;- md_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_md))\n\nmd_con_join &lt;- md_con_tidy %&gt;%\n  mutate(state = rep(\"Maryland\"))"
  },
  {
    "objectID": "statecons.html#massachusetts",
    "href": "statecons.html#massachusetts",
    "title": "State_constitutions",
    "section": "Massachusetts",
    "text": "Massachusetts\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nma_url &lt;- \"http://www.nhinet.org/ccs/docs/ma-1780.htm\"\nma_html &lt;- read_html(ma_url)\n\nma_text &lt;- html_text(ma_html)\n\nma_con &lt;- data.frame(word = unlist(strsplit(ma_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  \n\nrows_to_exclude_ma &lt;- c(11433:11445)\n\nma_con_tidy &lt;- ma_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_ma))\n\nma_con_join &lt;- ma_con_tidy %&gt;%\n  mutate(state = rep(\"Massachusetts\"))\n\n\nlibrary(tidyverse)\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n✔ readr     2.1.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()         masks stats::filter()\n✖ readr::guess_encoding() masks rvest::guess_encoding()\n✖ dplyr::lag()            masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidytext)\nma_word_count &lt;- ma_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word)\n\ndata(\"stop_words\")\nma_con_tidy_nostop &lt;- ma_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nma_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(art.\", \"\"))\n\n              word  n\n1             art. 87\n2             time 51\n3    commonwealth, 38\n4           public 34\n5     commonwealth 33\n6        governor, 32\n7            house 31\n8         governor 30\n9           shall, 27\n10          senate 26\n11           court 25\n12         persons 25\n13          people 23\n14      government 22\n15          person 21\n16 representatives 21\n17            town 21\n18        council, 20\n19           power 20\n20    constitution 19\n21           time, 19"
  },
  {
    "objectID": "statecons.html#new-jersey",
    "href": "statecons.html#new-jersey",
    "title": "State_constitutions",
    "section": "New Jersey",
    "text": "New Jersey\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nnj_url &lt;- \"https://avalon.law.yale.edu/18th_century/nj15.asp\"\nnj_html &lt;- read_html(nj_url)\n\nnj_text &lt;- html_text(nj_html)\n\nnj_con &lt;- data.frame(word = unlist(strsplit(nj_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  \n\nrows_to_exclude_nj &lt;- c(1:55, 2524:2889)\n\nnj_con_tidy &lt;- nj_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_nj))"
  },
  {
    "objectID": "statecons.html#new-york",
    "href": "statecons.html#new-york",
    "title": "State_constitutions",
    "section": "New York",
    "text": "New York\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nny_url &lt;- \"https://avalon.law.yale.edu/18th_century/ny01.asp\"\nny_html &lt;- read_html(ny_url)\n\nny_text &lt;- html_text(ny_html)\n\nny_con &lt;- data.frame(word = unlist(strsplit(ny_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  \n\nrows_to_exclude &lt;- c(1:68, 7813:8781)\n\nny_con_tidy &lt;- ny_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude))\n\nny_con_join &lt;- ny_con_tidy %&gt;%\n  mutate(state = rep(\"New York\"))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\n\nny_word_count &lt;- ny_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word)\n\ndata(\"stop_words\")\nny_con_tidy_nostop &lt;- ny_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nny_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n)\n\n              word  n\n1           people 39\n2           state, 37\n3           county 22\n4        authority 21\n5      legislature 20\n6           shall, 20\n7             time 20\n8         assembly 19\n9              \"he 18\n10      government 18\n11          senate 16\n12      convention 15\n13        further, 14\n14        senators 14\n15             day 13\n16            doth 13\n17            laws 13\n18         ordain, 13\n19          colony 12\n20           court 12\n21      determine, 12\n22          judges 12\n23           power 12\n24 representatives 12"
  },
  {
    "objectID": "statecons.html#north-carolina",
    "href": "statecons.html#north-carolina",
    "title": "State_constitutions",
    "section": "North Carolina",
    "text": "North Carolina\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nnc_url &lt;- \"https://avalon.law.yale.edu/18th_century/nc07.asp\"\nnc_html &lt;- read_html(nc_url)\n\nnc_text &lt;- html_text(nc_html)\n\nnc_con &lt;- data.frame(word = unlist(strsplit(nc_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  \n\nrows_to_exclude &lt;- c(1:58, 3991:4231)\n\nnc_con_tidy &lt;- nc_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude))\n\nnc_con_join &lt;- nc_con_tidy %&gt;%\n  mutate(state = rep(\"North Carolina\"))"
  },
  {
    "objectID": "statecons.html#pennsylvania",
    "href": "statecons.html#pennsylvania",
    "title": "State_constitutions",
    "section": "Pennsylvania",
    "text": "Pennsylvania\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\npa_url &lt;- \"https://avalon.law.yale.edu/18th_century/pa08.asp\"\npa_html &lt;- read_html(pa_url)\n\npa_text &lt;- html_text(pa_html)\n\npa_con &lt;- data.frame(word = unlist(strsplit(pa_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  \n\nrows_to_exclude &lt;- c(1:57, 6196:6533)\n\npa_con_tidy &lt;- pa_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude))\n\npa_con_join &lt;- pa_con_tidy %&gt;%\n  mutate(state = rep(\"Pennsylvania\"))"
  },
  {
    "objectID": "statecons.html#rhode-island",
    "href": "statecons.html#rhode-island",
    "title": "State_constitutions",
    "section": "Rhode Island",
    "text": "Rhode Island\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nri_url &lt;- \"https://www.wordservice.org/State%20Constitutions/usa1031.htm\"\nri_html &lt;- read_html(ri_url)\n\nri_text &lt;- html_text(ri_html)\n\nri_con &lt;- data.frame(word = unlist(strsplit(ri_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\"))  %&gt;%\n  filter(!word==\"\")\n\n\nrows_to_exclude_ri &lt;- c(1:200, 7322:7331)\n\nri_con_tidy &lt;- ri_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_ri))\n\nri_con_join &lt;- ri_con_tidy %&gt;%\n  mutate(state = rep(\"Rhode Island\"))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nri_word_count &lt;- ri_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word)\n\ndata(\"stop_words\")\nri_con_tidy_nostop &lt;- ri_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nri_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \"))\n\n              word  n\n1              sec 88\n2         assembly 47\n3              law 38\n4           person 35\n5         election 34\n6             time 34\n7             town 33\n8     constitution 30\n9           office 29\n10            city 28\n11        governor 27\n12           house 26\n13            vote 22\n14         elected 18\n15        officers 18\n16 representatives 17\n17         article 14\n18           court 14\n19        military 14\n20          people 14\n21       secretary 14"
  },
  {
    "objectID": "statecons.html#virginia",
    "href": "statecons.html#virginia",
    "title": "State_constitutions",
    "section": "Virginia",
    "text": "Virginia\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nva_url &lt;- \"https://www.wordservice.org/State%20Constitutions/usa1025.htm\"\nva_html &lt;- read_html(va_url)\n\nva_text &lt;- html_text(va_html)\n\nva_con &lt;- data.frame(word = unlist(strsplit(va_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  \n\nrows_to_exclude_va &lt;- c(1:201, 3680:3689)\n\nva_con_tidy &lt;- va_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_va))\n\nva_con_join &lt;- va_con_tidy %&gt;%\n  mutate(state = rep(\"Virgina\"))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nva_word_count &lt;- va_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word)\n\ndata(\"stop_words\")\nva_con_tidy_nostop &lt;- va_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nva_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \"))\n\n              word  n\n1            house 18\n2             sec. 15\n3           advice  9\n4      government,  9\n5             laws  9\n6        governor,  8\n7            privy  8\n8          appoint  7\n9           county  7\n10      government  7\n11          houses  7\n12           joint  7\n13          people  7\n14 representatives  7\n15        virginia  7\n16        assembly  6\n17          ballot  6\n18          chosen  6\n19         council  6\n20        council,  6\n21        exercise  6\n22            free  6\n23         people,  6\n24           power  6\n25          public  6\n26      respective  6\n27       virginia,  6"
  },
  {
    "objectID": "statecons.html#new-hampshire",
    "href": "statecons.html#new-hampshire",
    "title": "State_constitutions",
    "section": "New Hampshire",
    "text": "New Hampshire\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nnh_url &lt;- \"https://avalon.law.yale.edu/18th_century/nh09.asp\"\nnh_html &lt;- read_html(nh_url)\n\nnh_text &lt;- html_text(nh_html)\n\nnh_con &lt;- data.frame(word = unlist(strsplit(nh_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  \n\nrows_to_exclude_nh &lt;- c(1:63, 994:1242)\n\nnh_con_tidy &lt;- nh_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_nh))\n\nnh_con_join &lt;- nh_con_tidy %&gt;%\n  mutate(state = rep(\"New Hampshire\"))"
  },
  {
    "objectID": "statecons.html#south-carolina",
    "href": "statecons.html#south-carolina",
    "title": "State_constitutions",
    "section": "South Carolina",
    "text": "South Carolina\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nsc_url &lt;- \"https://avalon.law.yale.edu/18th_century/sc02.asp\"\nsc_html &lt;- read_html(sc_url)\n\nsc_text &lt;- html_text(sc_html)\n\nsc_con &lt;- data.frame(word = unlist(strsplit(sc_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  \n\nrows_to_exclude &lt;- c(1:58, 5639:5880)\n\nsc_con_tidy &lt;- sc_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude))\n\nsc_con_join &lt;- sc_con_tidy %&gt;%\n  mutate(state = rep(\"South Carolina\"))"
  },
  {
    "objectID": "statecons.html#federal",
    "href": "statecons.html#federal",
    "title": "State_constitutions",
    "section": "Federal",
    "text": "Federal\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nfederal_url &lt;- \"https://www.usconstitution.net/const-html/\"\nfederal_html &lt;- read_html(federal_url)\n\nfederal_text &lt;- html_text(federal_html)\n\nfederal_con &lt;- data.frame(word = unlist(strsplit(federal_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\" & word != \"-\" & word != \"=\" & !str_detect(word, \"[[:punct:]]\")) %&gt;%\n  mutate(word = str_trim(word))\n\nrows_to_exclude_federal &lt;- c(1:1900, 10012:11573)\n\nfederal_con_tidy &lt;- federal_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_federal))\n\nfederal_con_join &lt;- federal_con_tidy %&gt;%\n  mutate(state = rep(\"Federal\"))\n\n\nfederal_word_count &lt;- federal_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word)\n\ndata(\"stop_words\")\nfederal_con_tidy_nostop &lt;- federal_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nfederal_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \"))\n\n              word  n\n1           united 69\n2        president 65\n3         congress 38\n4        amendment 37\n5         ratified 30\n6           person 29\n7          article 24\n8             vice 22\n9           office 20\n10           power 19\n11        citizens 18\n12             law 18\n13            time 18\n14         section 16\n15          powers 15\n16 representatives 15\n17    constitution 14\n18          duties 14\n19         history 14\n20            note 13\n\nfederal_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  top_n(20) %&gt;%\n  ggplot(aes(y = fct_reorder(word, n), x = n, fill = n)) +\n  geom_col() +\n  guides(fill = FALSE) +\n  labs(y = \"Most Common Words\")\n\nSelecting by n\n\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4."
  },
  {
    "objectID": "presentation.html#does-the-time-a-state-came-into-being-affect-the-keywords-used-in-its-constitution",
    "href": "presentation.html#does-the-time-a-state-came-into-being-affect-the-keywords-used-in-its-constitution",
    "title": "State Constitution Analysis",
    "section": "Does the time a state came into being affect the keywords used in its Constitution?",
    "text": "Does the time a state came into being affect the keywords used in its Constitution?\nWe scraped text from the constitutions of the original 13 colonies and analyzed each for specific keywords.\n\nKeywords: freedom, liberty, welfare, consent, prohibit, equality, and rights"
  },
  {
    "objectID": "presentation.html#does-the-time-a-state-came-into-being-affect-the-keywords-used-in-its-constitution-1",
    "href": "presentation.html#does-the-time-a-state-came-into-being-affect-the-keywords-used-in-its-constitution-1",
    "title": "State Constitution Analysis",
    "section": "Does the time a state came into being affect the keywords used in its Constitution?",
    "text": "Does the time a state came into being affect the keywords used in its Constitution?\nThen, we created an interactive map using a time variable to be able to see when each state was ratified.\nGoal: to understand if the time a state was ratified has a large effect on the language used in the constitution."
  },
  {
    "objectID": "presentation.html#game-plan",
    "href": "presentation.html#game-plan",
    "title": "State Constitution Analysis",
    "section": "Game plan",
    "text": "Game plan\n\nScrape text from each constitution and create separate dataframes for each\nFind frequencies of chosen keywords in each constitution\nAlso analyze the top 20 words appearing most frequently in each constitution (minus common stop words)\nCreate histograms of the most common words\nLink dataframes together into one dataframe to create maps\nCreated character variable for each word with what state it was from, then used the tigris package with state geometry to create a map (keywords!)\nCreate interactive map!"
  },
  {
    "objectID": "presentation.html#ratification-years",
    "href": "presentation.html#ratification-years",
    "title": "State Constitution Analysis",
    "section": "Ratification years",
    "text": "Ratification years\n\n\n\nstate\nyear\n\n\n\n\nDelaware\n1787\n\n\nGeorgia\n1777\n\n\nConnecticut\n1818\n\n\nMaryland\n1776\n\n\nMassachusetts\n1780\n\n\nNew Hampshire\n1776\n\n\nNew Jersey\n1776\n\n\nNew York\n1777\n\n\nNorth Carolina\n1776\n\n\nPennsylvania\n1776\n\n\nRhode Island\n1843\n\n\nSouth Carolina\n1778\n\n\nVirginia\n1776"
  },
  {
    "objectID": "presentation.html#word-frequencies-virginia",
    "href": "presentation.html#word-frequencies-virginia",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: Virginia",
    "text": "Word frequencies: Virginia\nRatification year: 1776\n\nMost common wordsHistogram\n\n\n\n\n              word  n\n1       government 19\n2            house 19\n3         assembly 16\n4           people 16\n5              sec 15\n6         virginia 15\n7          council 14\n8         governor 14\n9        delegates 13\n10            laws 12\n11          office 11\n12          houses 10\n13          advice  9\n14          county  9\n15             law  9\n16            time  9\n17       vacancies  9\n18        annually  8\n19          courts  8\n20          manner  8\n21           power  8\n22           privy  8\n23 representatives  8\n24          rights  8"
  },
  {
    "objectID": "presentation.html#word-frequencies-pennsylvania",
    "href": "presentation.html#word-frequencies-pennsylvania",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: Pennsylvania",
    "text": "Word frequencies: Pennsylvania\nRatification year: 1776\n\nMost common wordsHistogram\n\n\n\n\n              word  n\n1             sect 47\n2         assembly 41\n3     commonwealth 28\n4           people 28\n5          council 24\n6           county 22\n7  representatives 22\n8          freemen 21\n9       government 21\n10          office 20\n11            laws 19\n12            city 17\n13          public 16\n14     legislature 15\n15           power 15\n16          manner 14\n17        officers 14\n18          person 14\n19          chosen 13\n20    constitution 13\n21        counties 13\n22         elected 13\n23            free 13\n24    pennsylvania 13\n25         persons 13\n26            time 13"
  },
  {
    "objectID": "presentation.html#word-frequencies-maryland",
    "href": "presentation.html#word-frequencies-maryland",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: Maryland",
    "text": "Word frequencies: Maryland\nRatification year: 1776\n\nMost common wordsHistogram\n\n\n\n\n          word  n\n1       person 59\n2       office 49\n3     governor 42\n4       county 41\n5    delegates 38\n6      council 35\n7        court 32\n8     assembly 31\n9         time 31\n10    election 29\n11         law 28\n12 legislature 27\n13       house 24\n14  government 21\n15        oath 21\n16     persons 21\n17   aforesaid 20\n18      ballot 20\n19      manner 20\n20       money 18\n21   qualified 18"
  },
  {
    "objectID": "presentation.html#word-frequencies-new-jersey",
    "href": "presentation.html#word-frequencies-new-jersey",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: New Jersey",
    "text": "Word frequencies: New Jersey\nRatification year: 1776\n\nMost common wordsHistogram\n\n\n\n\n              word  n\n1          council 28\n2         assembly 26\n3           colony 26\n4         governor 12\n5           county 10\n6           person 10\n7       government  9\n8          elected  8\n9              law  8\n10     legislative  8\n11        officers  8\n12            time  8\n13         charter  7\n14          manner  7\n15   vicepresident  7\n16        election  6\n17          people  6\n18 representatives  6\n19          choose  5\n20        colonies  5\n21        congress  5\n22        counties  5\n23           court  5\n24          office  5\n25         persons  5\n26           power  5\n27        provided  5\n28        province  5\n29          remain  5\n30         supreme  5\n31            vote  5"
  },
  {
    "objectID": "presentation.html#word-frequencies-new-hampshire",
    "href": "presentation.html#word-frequencies-new-hampshire",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: New Hampshire",
    "text": "Word frequencies: New Hampshire\nRatification year: 1776\n\nMost common wordsHistogram\n\n\n\n\n              word  n\n1          council 12\n2           county 12\n3           colony 11\n4         congress  8\n5        appointed  7\n6         assembly  6\n7            house  6\n8         officers  6\n9           courts  5\n10 representatives  5\n11         britain  4\n12          chosen  4\n13          manner  4\n14          people  4\n15      respective  4\n16     continental  3\n17        continue  3\n18            form  3\n19      government  3\n20          houses  3\n21     inhabitants  3\n22           lives  3\n23      properties  3\n24            time  3\n25         unhappy  3"
  },
  {
    "objectID": "presentation.html#word-frequencies-north-carolina",
    "href": "presentation.html#word-frequencies-north-carolina",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: North Carolina",
    "text": "Word frequencies: North Carolina\nRatification year: 1776\n\nMost common wordsHistogram\n\n\n\n\n              word  n\n1            house 27\n2         assembly 24\n3          commons 20\n4           senate 19\n5           office 16\n6         governor 14\n7           county 13\n8       government 12\n9           people 12\n10         council 11\n11          public 11\n12                 10\n13            time 10\n14          ballot  9\n15        election  9\n16            laws  9\n17         liberty  9\n18          person  9\n19    constitution  8\n20             law  8\n21           power  8\n22 representatives  8\n23            seat  8"
  },
  {
    "objectID": "presentation.html#word-frequencies-new-york",
    "href": "presentation.html#word-frequencies-new-york",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: New York",
    "text": "Word frequencies: New York\nRatification year: 1777\n\nMost common wordsHistogram\n\n\n\n\n          word  n\n1       people 46\n2  legislature 37\n3         time 29\n4   government 28\n5     assembly 27\n6       county 26\n7    authority 22\n8       senate 22\n9        court 21\n10        york 20\n11  convention 19\n12    governor 19\n13      office 19\n14      colony 18\n15   appointed 17\n16    congress 17\n17        laws 17\n18         day 16\n19   determine 16\n20    senators 16"
  },
  {
    "objectID": "presentation.html#word-frequencies-georgia",
    "href": "presentation.html#word-frequencies-georgia",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: Georgia",
    "text": "Word frequencies: Georgia\nRatification year: 1777\n\nMost common wordsHistogram\n\n\n\n\n              word  n\n1              art 62\n2           county 49\n3            house 23\n4         assembly 22\n5          council 22\n6           person 19\n7         governor 18\n8        executive 17\n9     constitution 15\n10 representatives 14\n11        election 13\n12           power 13\n13            laws 12\n14           saint 12\n15            time 12\n16        counties 11\n17           court 10\n18         elected 10\n19         tuesday 10\n20            vote 10"
  },
  {
    "objectID": "presentation.html#word-frequencies-south-carolina",
    "href": "presentation.html#word-frequencies-south-carolina",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: South Carolina",
    "text": "Word frequencies: South Carolina\nRatification year: 1778\n\nMost common wordsHistogram\n\n\n\n\n                 word  n\n1               house 53\n2     representatives 49\n3              parish 39\n4              senate 39\n5             council 30\n6            governor 30\n7            district 29\n8               privy 28\n9    commanderinchief 22\n10              saint 21\n11             chosen 20\n12             office 18\n13           election 17\n14                law 16\n15 lieutenantgovernor 16\n16             person 15\n17               time 15\n18           assembly 13\n19               seat 13\n20       constitution 12\n21                day 12\n22          religious 12"
  },
  {
    "objectID": "presentation.html#word-frequencies-massachusetts",
    "href": "presentation.html#word-frequencies-massachusetts",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: Massachusetts",
    "text": "Word frequencies: Massachusetts\nRatification year: 1780\n\nMost common wordsHistogram\n\n\n\n\n              word  n\n1              art 87\n2     commonwealth 86\n3             time 72\n4         governor 67\n5     constitution 42\n6  representatives 41\n7            court 39\n8       government 38\n9            house 38\n10          public 37\n11          people 36\n12         council 35\n13            laws 35\n14     legislature 35\n15          senate 35\n16        officers 31\n17         persons 30\n18          person 29\n19          manner 27\n20       authority 26\n21         elected 26\n22           power 26"
  },
  {
    "objectID": "presentation.html#word-frequencies-delaware",
    "href": "presentation.html#word-frequencies-delaware",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: Delaware",
    "text": "Word frequencies: Delaware\nRatification year: 1787\n\nMost common wordsHistogram\n\n\n\n\n          word  n\n1          art 59\n2     assembly 42\n3      council 26\n4        house 26\n5       office 25\n6    president 22\n7     election 19\n8       courts 15\n9          day 15\n10        time 15\n11      chosen 14\n12      county 14\n13 legislative 13\n14       privy 13\n15       court 12\n16      manner 12\n17             11\n18    delaware 11\n19    justices 11\n20      common 10"
  },
  {
    "objectID": "presentation.html#word-frequencies-connecticut",
    "href": "presentation.html#word-frequencies-connecticut",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: Connecticut",
    "text": "Word frequencies: Connecticut\nRatification year: 1818\n\nMost common wordsHistogram\n\n\n\n\n           word   n\n1           sec 100\n2           art  94\n3      assembly  44\n4     governour  36\n5           law  35\n6         house  25\n7        office  25\n8    amendments  23\n9       altered  22\n10        votes  21\n11            4  20\n12     electors  20\n13       manner  20\n14 constitution  19\n15       person  19\n16         time  19\n17            3  18\n18    secretary  18\n19            6  17\n20            2  15\n21         town  15"
  },
  {
    "objectID": "presentation.html#word-frequencies-rhode-island",
    "href": "presentation.html#word-frequencies-rhode-island",
    "title": "State Constitution Analysis",
    "section": "Word frequencies: Rhode Island",
    "text": "Word frequencies: Rhode Island\nRatification year: 1843\n\nMost common wordsHistogram\n\n\n\n\n              word  n\n1              sec 88\n2         assembly 47\n3              law 38\n4           person 35\n5         election 34\n6             time 34\n7             town 33\n8     constitution 30\n9           office 29\n10            city 28\n11        governor 27\n12           house 26\n13            vote 22\n14         elected 18\n15        officers 18\n16 representatives 17\n17         article 14\n18           court 14\n19        military 14\n20          people 14\n21       secretary 14"
  },
  {
    "objectID": "presentation.html#keyword-maps",
    "href": "presentation.html#keyword-maps",
    "title": "State Constitution Analysis",
    "section": "Keyword Maps",
    "text": "Keyword Maps\n\nFreedomLibertyWelfareConsentProhibitEqualityRights"
  },
  {
    "objectID": "presentation.html#most-common-words-across-all-13-states",
    "href": "presentation.html#most-common-words-across-all-13-states",
    "title": "State Constitution Analysis",
    "section": "Most common words across all 13 states",
    "text": "Most common words across all 13 states"
  },
  {
    "objectID": "presentation.html#conclusions",
    "href": "presentation.html#conclusions",
    "title": "State Constitution Analysis",
    "section": "Conclusions",
    "text": "Conclusions\n\nThe most common words have to do with administration rather than ideology\nEx. section, article, council, county, government, people\nEven though the map is a useful visualization, there don’t seem to be geographical trends &gt;&gt;&gt;&gt;&gt;&gt;&gt; Stashed changes"
  },
  {
    "objectID": "statecons.html#colonies-data-frame-and-map",
    "href": "statecons.html#colonies-data-frame-and-map",
    "title": "State_constitutions",
    "section": "13 colonies data frame and map",
    "text": "13 colonies data frame and map\n\nlibrary(tmap)\n\nBreaking News: tmap 3.x is retiring. Please test v4, e.g. with\nremotes::install_github('r-tmap/tmap')\n\nlibrary(tigris)\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\nthirteen_cons &lt;- rbind(ct_con_join,\n                       de_con_join,\n                       ga_con_join,\n                       ma_con_join,\n                       md_con_join,\n                       nc_con_join,\n                       nh_con_join,\n                       ny_con_join,\n                       pa_con_join,\n                       ri_con_join,\n                       sc_con_join,\n                       va_con_join)"
  },
  {
    "objectID": "mapdoc.html",
    "href": "mapdoc.html",
    "title": "mapdoc",
    "section": "",
    "text": "Connecticut: https://www.cga.ct.gov/asp/Content/constitutions/1818Constitution.htm (Basil-Anne)\nDelaware: https://avalon.law.yale.edu/18th_century/de02.asp (Basil-Anne)\nGeorgia: https://avalon.law.yale.edu/18th_century/ga02.asp (Katie)\nMaryland: https://avalon.law.yale.edu/17th_century/ma02.asp (Katie)\nMassachusetts: http://www.nhinet.org/ccs/docs/ma-1780.htm (Basil-Anne)\nNew Hampshire: https://avalon.law.yale.edu/18th_century/nh09.asp (Katie)\nNew Jersey: https://avalon.law.yale.edu/18th_century/nj15.asp (Katie)\nNew York: https://avalon.law.yale.edu/18th_century/ny01.asp (Cassie)\nNorth Carolina: https://avalon.law.yale.edu/18th_century/nc07.asp (Cassie)\nPennsylvania: https://avalon.law.yale.edu/18th_century/pa08.asp (Cassie)\nRhode Island: https://www.wordservice.org/State%20Constitutions/usa1031.htm (Basil-Anne)\nSouth Carolina: https://avalon.law.yale.edu/18th_century/sc02.asp (Cassie)\nVirginia: https://www.wordservice.org/State%20Constitutions/usa1025.htm (Basil-Anne)"
  },
  {
    "objectID": "mapdoc.html#list-of-states",
    "href": "mapdoc.html#list-of-states",
    "title": "mapdoc",
    "section": "",
    "text": "Connecticut: https://www.cga.ct.gov/asp/Content/constitutions/1818Constitution.htm (Basil-Anne)\nDelaware: https://avalon.law.yale.edu/18th_century/de02.asp (Basil-Anne)\nGeorgia: https://avalon.law.yale.edu/18th_century/ga02.asp (Katie)\nMaryland: https://avalon.law.yale.edu/17th_century/ma02.asp (Katie)\nMassachusetts: http://www.nhinet.org/ccs/docs/ma-1780.htm (Basil-Anne)\nNew Hampshire: https://avalon.law.yale.edu/18th_century/nh09.asp (Katie)\nNew Jersey: https://avalon.law.yale.edu/18th_century/nj15.asp (Katie)\nNew York: https://avalon.law.yale.edu/18th_century/ny01.asp (Cassie)\nNorth Carolina: https://avalon.law.yale.edu/18th_century/nc07.asp (Cassie)\nPennsylvania: https://avalon.law.yale.edu/18th_century/pa08.asp (Cassie)\nRhode Island: https://www.wordservice.org/State%20Constitutions/usa1031.htm (Basil-Anne)\nSouth Carolina: https://avalon.law.yale.edu/18th_century/sc02.asp (Cassie)\nVirginia: https://www.wordservice.org/State%20Constitutions/usa1025.htm (Basil-Anne)"
  },
  {
    "objectID": "mapdoc.html#connecticut",
    "href": "mapdoc.html#connecticut",
    "title": "mapdoc",
    "section": "Connecticut",
    "text": "Connecticut\n\nlibrary(rvest)\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.4\n✔ ggplot2   3.5.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()         masks stats::filter()\n✖ readr::guess_encoding() masks rvest::guess_encoding()\n✖ dplyr::lag()            masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidytext)\n\nct_url &lt;- \"https://www.cga.ct.gov/asp/Content/constitutions/1818Constitution.htm\"\nct_html &lt;- read_html(ct_url)\n\nct_text &lt;- html_text(ct_html)\n\nct_con &lt;- data.frame(word = unlist(strsplit(ct_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) %&gt;%\n  filter(!word== \"\")\n\nrows_to_exclude_ct &lt;- c(1:7, 223:298, 6012:12230)\n\nct_con_tidy &lt;- ct_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_ct))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\n\nct_word_count &lt;- ct_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) \n\ndata(\"stop_words\")\nct_con_tidy_nostop &lt;- ct_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nct_all_words &lt;- ct_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  mutate(state = rep(\"Connecticut\"))"
  },
  {
    "objectID": "mapdoc.html#delaware",
    "href": "mapdoc.html#delaware",
    "title": "mapdoc",
    "section": "Delaware",
    "text": "Delaware\n\nlibrary(rvest)\nlibrary(dplyr)\n\nde_url &lt;- \"https://avalon.law.yale.edu/18th_century/de02.asp\"\nde_html &lt;- read_html(de_url)\n\nde_text &lt;- html_text(de_html)\n\nde_con &lt;- data.frame(word = unlist(strsplit(de_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) \n\nrows_to_exclude &lt;- c(1:54, 3721:3796)\n\nde_con_tidy &lt;- de_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nde_word_count &lt;- de_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"Delaware\"))\n\n\ndata(\"stop_words\")\nde_con_tidy_nostop &lt;- de_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nde_all_words &lt;- de_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  mutate(state = rep(\"Delaware\"))"
  },
  {
    "objectID": "mapdoc.html#georgia",
    "href": "mapdoc.html#georgia",
    "title": "mapdoc",
    "section": "Georgia",
    "text": "Georgia\n\nlibrary(rvest)\nlibrary(dplyr)\n\nga_url &lt;- \"https://avalon.law.yale.edu/18th_century/ga02.asp\"\nga_html &lt;- read_html(ga_url)\n\nga_text &lt;- html_text(ga_html)\n\nga_con &lt;- data.frame(word = unlist(strsplit(ga_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) \n\nrows_to_exclude_ga &lt;- c(1:56, 4422:4652)\n\nga_con_tidy &lt;- ga_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_ga))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nga_word_count &lt;- ga_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"Georgia\"))\n\n\ndata(\"stop_words\")\nga_con_tidy_nostop &lt;- ga_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nga_all_words &lt;- ga_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  mutate(state = rep(\"Georgia\"))"
  },
  {
    "objectID": "mapdoc.html#maryland",
    "href": "mapdoc.html#maryland",
    "title": "mapdoc",
    "section": "Maryland",
    "text": "Maryland\n\nlibrary(rvest)\nlibrary(dplyr)\n\nmd_url &lt;- \"https://avalon.law.yale.edu/17th_century/ma02.asp\"\nmd_html &lt;- read_html(md_url)\n\nmd_text &lt;- html_text(md_html)\n\nmd_con &lt;- data.frame(word = unlist(strsplit(md_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) \n\nrows_to_exclude_md &lt;- c(1:94, 2623:2669, 8854:9084)\n\nmd_con_tidy &lt;- md_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_md))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nmd_word_count &lt;- md_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"Maryland\"))\n\n\ndata(\"stop_words\")\nmd_con_tidy_nostop &lt;- md_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nmd_all_words &lt;- md_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  mutate(state = rep(\"Maryland\"))"
  },
  {
    "objectID": "mapdoc.html#massachusetts",
    "href": "mapdoc.html#massachusetts",
    "title": "mapdoc",
    "section": "Massachusetts",
    "text": "Massachusetts\n\nma_url &lt;- \"http://www.nhinet.org/ccs/docs/ma-1780.htm\"\nma_html &lt;- read_html(ma_url)\n\nma_text &lt;- html_text(ma_html)\n\nma_con &lt;- data.frame(word = unlist(strsplit(ma_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) \n\nrows_to_exclude_ma &lt;- c(11433:11445)\n\nma_con_tidy &lt;- ma_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  mutate(word=gsub(\"[[:space:]]\", \"\", word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_ma))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nma_word_count &lt;- ma_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"Massachusetts\"))\n\n\ndata(\"stop_words\")\nma_con_tidy_nostop &lt;- ma_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nma_all_words &lt;- ma_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(art.\", \"\")) %&gt;%\n  mutate(state = rep(\"Massachusetts\"))"
  },
  {
    "objectID": "mapdoc.html#new-hampshire",
    "href": "mapdoc.html#new-hampshire",
    "title": "mapdoc",
    "section": "New Hampshire",
    "text": "New Hampshire\n\nlibrary(rvest)\nlibrary(dplyr)\n\nnh_url &lt;- \"https://avalon.law.yale.edu/18th_century/nh09.asp\"\nnh_html &lt;- read_html(nh_url)\n\nnh_text &lt;- html_text(nh_html)\n\nnh_con &lt;- data.frame(word = unlist(strsplit(nh_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) \n\nrows_to_exclude_nh &lt;- c(1:63, 994:1242)\n\nnh_con_tidy &lt;- nh_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_nh))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nnh_word_count &lt;- nh_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"New Hampshire\"))\n\n\ndata(\"stop_words\")\nnh_con_tidy_nostop &lt;- nh_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nnh_all_words &lt;- nh_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(art.\", \" \")) %&gt;%\n  mutate(state = rep(\"New Hampshire\"))"
  },
  {
    "objectID": "mapdoc.html#new-jersey",
    "href": "mapdoc.html#new-jersey",
    "title": "mapdoc",
    "section": "New Jersey",
    "text": "New Jersey\n\nlibrary(rvest)\nlibrary(dplyr)\n\nnj_url &lt;- \"https://avalon.law.yale.edu/18th_century/nj15.asp\"\nnj_html &lt;- read_html(nj_url)\n\nnj_text &lt;- html_text(nj_html)\n\nnj_con &lt;- data.frame(word = unlist(strsplit(nj_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) \n\nrows_to_exclude_nj &lt;- c(1:55, 2524:2889)\n\nnj_con_tidy &lt;- nj_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_nj))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nnj_word_count &lt;- nj_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"New Jersey\"))\n\n\ndata(\"stop_words\")\nnj_con_tidy_nostop &lt;- nj_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nnj_all_words &lt;- nj_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(art.\", \" \"))  %&gt;%\n  mutate(state = rep(\"New Jersey\"))"
  },
  {
    "objectID": "mapdoc.html#new-york",
    "href": "mapdoc.html#new-york",
    "title": "mapdoc",
    "section": "New York",
    "text": "New York\n\nlibrary(rvest)\nlibrary(dplyr)\n\nny_url &lt;- \"https://avalon.law.yale.edu/18th_century/ny01.asp\"\nny_html &lt;- read_html(ny_url)\n\nny_text &lt;- html_text(ny_html)\n\nny_con &lt;- data.frame(word = unlist(strsplit(ny_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) \n\nrows_to_exclude &lt;- c(1:68, 7813:8781)\n\nny_con_tidy &lt;- ny_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\n\nny_word_count &lt;- ny_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"New York\"))\n\n\ndata(\"stop_words\")\nny_con_tidy_nostop &lt;- ny_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nny_all_words &lt;- ny_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  mutate(state = rep(\"New York\"))"
  },
  {
    "objectID": "mapdoc.html#north-carolina",
    "href": "mapdoc.html#north-carolina",
    "title": "mapdoc",
    "section": "North Carolina",
    "text": "North Carolina\n\nlibrary(rvest)\nlibrary(dplyr)\n\nnc_url &lt;- \"https://avalon.law.yale.edu/18th_century/nc07.asp\"\nnc_html &lt;- read_html(nc_url)\n\nnc_text &lt;- html_text(nc_html)\n\nnc_con &lt;- data.frame(word = unlist(strsplit(nc_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) \n\nrows_to_exclude &lt;- c(1:58, 3991:4231)\n\nnc_con_tidy &lt;- nc_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nnc_word_count &lt;- nc_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"North Carolina\"))\n\n\ndata(\"stop_words\")\nnc_con_tidy_nostop &lt;- nc_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nnc_all_words &lt;- nc_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \")) %&gt;%\n  mutate(state = rep(\"North Carolina\"))"
  },
  {
    "objectID": "mapdoc.html#pennsylvania",
    "href": "mapdoc.html#pennsylvania",
    "title": "mapdoc",
    "section": "Pennsylvania",
    "text": "Pennsylvania\n\nlibrary(rvest)\nlibrary(dplyr)\n\npa_url &lt;- \"https://avalon.law.yale.edu/18th_century/pa08.asp\"\npa_html &lt;- read_html(pa_url)\n\npa_text &lt;- html_text(pa_html)\n\npa_con &lt;- data.frame(word = unlist(strsplit(pa_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) \n\nrows_to_exclude &lt;- c(1:57, 6196:6533)\n\npa_con_tidy &lt;- pa_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\npa_word_count &lt;- pa_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"Pennsylvania\"))\n\n\ndata(\"stop_words\")\npa_con_tidy_nostop &lt;- pa_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\npa_all_words &lt;- pa_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \")) %&gt;%\n  mutate(state = rep(\"Pennsylvania\"))"
  },
  {
    "objectID": "mapdoc.html#rhode-island",
    "href": "mapdoc.html#rhode-island",
    "title": "mapdoc",
    "section": "Rhode Island",
    "text": "Rhode Island\n\nri_url &lt;- \"https://www.wordservice.org/State%20Constitutions/usa1031.htm\"\nri_html &lt;- read_html(ri_url)\n\nri_text &lt;- html_text(ri_html)\n\nri_con &lt;- data.frame(word = unlist(strsplit(ri_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) %&gt;%\n  filter(!word== \"\")\n\n\nrows_to_exclude_ri &lt;- c(1:200, 7322:7331)\n\nri_con_tidy &lt;- ri_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_ri))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nri_word_count &lt;- ri_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"Rhode Island\"))\n\n\ndata(\"stop_words\")\nri_con_tidy_nostop &lt;- ri_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nri_all_words &lt;- ri_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \")) %&gt;%\n  mutate(state = rep(\"Rhode Island\"))"
  },
  {
    "objectID": "mapdoc.html#south-carolina",
    "href": "mapdoc.html#south-carolina",
    "title": "mapdoc",
    "section": "South Carolina",
    "text": "South Carolina\n\nlibrary(rvest)\nlibrary(dplyr)\n\nsc_url &lt;- \"https://avalon.law.yale.edu/18th_century/sc02.asp\"\nsc_html &lt;- read_html(sc_url)\n\nsc_text &lt;- html_text(sc_html)\n\nsc_con &lt;- data.frame(word = unlist(strsplit(sc_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) \n\nrows_to_exclude &lt;- c(1:58, 5639:5880)\n\nsc_con_tidy &lt;- sc_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nsc_word_count &lt;- sc_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"South Carolina\"))\n\n\ndata(\"stop_words\")\nsc_con_tidy_nostop &lt;- sc_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nsc_all_words &lt;- sc_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \"))  %&gt;%\n  mutate(state = rep(\"South Carolina\"))"
  },
  {
    "objectID": "mapdoc.html#virginia",
    "href": "mapdoc.html#virginia",
    "title": "mapdoc",
    "section": "Virginia",
    "text": "Virginia\n\nva_url &lt;- \"https://www.wordservice.org/State%20Constitutions/usa1025.htm\"\nva_html &lt;- read_html(va_url)\n\nva_text &lt;- html_text(va_html)\n\nva_con &lt;- data.frame(word = unlist(strsplit(va_text, \"\\\\s+\"))) %&gt;%\n  filter(word != \"\")  %&gt;%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) \n\nrows_to_exclude_va &lt;- c(1:201, 3680:3689)\n\nva_con_tidy &lt;- va_con %&gt;%\n  mutate(word = tolower(word)) %&gt;%\n  filter(!(row_number() %in% rows_to_exclude_va))\n\n\nlibrary(tidyverse)\nlibrary(tidytext)\nva_word_count &lt;- va_con_tidy %&gt;%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %&gt;%\n  count(word) %&gt;%\n  mutate(state = rep(\"Virginia\"))\n\n\ndata(\"stop_words\")\nva_con_tidy_nostop &lt;- va_con_tidy %&gt;%\n anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\nva_all_words &lt;- va_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n    slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \")) %&gt;%\n  mutate(state = rep(\"Virginia\"))\n\n\nct_word_count &lt;- ct_word_count %&gt;%\n  mutate(state = rep(\"Connecticut\"))\n\nde_word_count &lt;- de_word_count %&gt;%\n  mutate(state = rep(\"Delaware\"))\n\nga_word_count &lt;- ga_word_count %&gt;%\n  mutate(state = rep(\"Georgia\"))\n\nma_word_count &lt;- ma_word_count %&gt;%\n  mutate(state = rep(\"Massachusetts\"))\n\nmd_word_count &lt;- md_word_count %&gt;%\n  mutate(state = rep(\"Maryland\"))\n\nnc_word_count &lt;- nc_word_count %&gt;%\n  mutate(state = rep(\"North Carolina\"))\n\nnh_word_count &lt;- nh_word_count %&gt;%\n  mutate(state = rep(\"New Hampshire\"))\n\nnj_word_count &lt;- nj_word_count %&gt;%\n  mutate(state = rep(\"New Jersey\"))\n\nny_word_count &lt;- ny_word_count %&gt;%\n  mutate(state = rep(\"New York\"))\n\npa_word_count &lt;- pa_word_count %&gt;%\n  mutate(state = rep(\"Pennsylvania\"))\n\nri_word_count &lt;- ri_word_count %&gt;%\n  mutate(state = rep(\"Rhode Island\"))\n\nsc_word_count &lt;- sc_word_count %&gt;%\n  mutate(state = rep(\"South Carolina\"))\n\nva_word_count &lt;- va_word_count %&gt;%\n  mutate(state = rep(\"Virginia\"))\n\n\nlibrary(tmap)\n\nBreaking News: tmap 3.x is retiring. Please test v4, e.g. with\nremotes::install_github('r-tmap/tmap')\n\nlibrary(tigris)\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\nlibrary(tidyr)\n\nthirteen_cons &lt;- rbind(ct_word_count,\n                       de_word_count,\n                       ga_word_count,\n                       ma_word_count,\n                       md_word_count,\n                       nc_word_count,\n                       nh_word_count,\n                       nj_word_count,\n                       ny_word_count,\n                       pa_word_count,\n                       ri_word_count,\n                       sc_word_count,\n                       va_word_count)\nstates &lt;- states()\n\nRetrieving data for the year 2021\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |                                                                      |   1%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=======                                                               |  11%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |==============                                                        |  21%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |===================                                                   |  28%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |=====================                                                 |  31%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |=======================                                               |  34%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |============================                                          |  41%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |==============================                                        |  44%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |========================================                              |  58%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |==========================================                            |  61%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |=================================================                     |  71%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |===============================================================       |  91%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================|  99%\n  |                                                                            \n  |======================================================================| 100%\n\nmap_data &lt;- thirteen_cons %&gt;% \n  left_join(states, join_by(state == NAME)) %&gt;%\n  pivot_wider(names_from = word, values_from = n)\n\nfreedom_map &lt;- ggplot(map_data, aes(fill = freedom)) + geom_sf(aes(geometry = geometry))\nfreedom_map\n\n\n\n\n\n\n\n\n\nliberty_map &lt;- ggplot(map_data, aes(fill = liberty)) + geom_sf(aes(geometry = geometry))\nliberty_map\n\n\n\n\n\n\n\n\n\nwelfare_map &lt;- ggplot(map_data, aes(fill = welfare)) + geom_sf(aes(geometry = geometry))\nwelfare_map\n\n\n\n\n\n\n\n\n\nconsent_map &lt;- ggplot(map_data, aes(fill = consent)) + geom_sf(aes(geometry = geometry))\nconsent_map\n\n\n\n\n\n\n\n\n\nprohibit_map &lt;- ggplot(map_data, aes(fill = prohibit)) + geom_sf(aes(geometry = geometry))\nprohibit_map\n\n\n\n\n\n\n\n\n\nequality_map &lt;- ggplot(map_data, aes(fill = equality)) + geom_sf(aes(geometry = geometry))\nequality_map\n\n\n\n\n\n\n\n\n\nrights_map &lt;- ggplot(map_data, aes(fill = rights)) + geom_sf(aes(geometry = geometry))\nrights_map\n\n\n\n\n\n\n\n\n\nyear_values &lt;- c(rep(1818, nrow(ct_word_count)),\n                 rep(1776, nrow(de_word_count)),\n                 rep(1777, nrow(ga_word_count)),\n                 rep(1780, nrow(ma_word_count)),\n                 rep(1776, nrow(md_word_count)),\n                 rep(1776, nrow(nc_word_count)),\n                 rep(1776, nrow(nh_word_count)),\n                 rep(1776, nrow(nj_word_count)),\n                 rep(1777, nrow(ny_word_count)),\n                 rep(1776, nrow(pa_word_count)),\n                 rep(1843, nrow(ri_word_count)),\n                 rep(1778, nrow(sc_word_count)),\n                 rep(1776, nrow(va_word_count)))\n\n\nthirteen_cons$year &lt;- year_values\n\nmap_data_2 &lt;- thirteen_cons %&gt;% \n  left_join(states, join_by(state == NAME)) %&gt;%\n  pivot_wider(names_from = word, values_from = n)\n\nmap_data_2$year &lt;- as.character(map_data_2$year)\n\ntime_map &lt;- ggplot(map_data_2, aes(fill = year)) + geom_sf(aes(geometry = geometry))\ntime_map\n\n\n\n\n\n\n\n\n\nct_all_words &lt;- ct_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  mutate(state = rep(\"Connecticut\"))\n\n\nde_all_words &lt;- de_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  mutate(state = rep(\"Delaware\"))\n\nga_all_words &lt;- ga_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  mutate(state = rep(\"Georgia\"))\n\nmd_all_words &lt;- md_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  mutate(state = rep(\"Maryland\"))\n\nma_all_words &lt;- ma_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(art.\", \"\")) %&gt;%\n  mutate(state = rep(\"Massachusetts\"))\n\nnh_all_words &lt;- nh_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(art.\", \" \")) %&gt;%\n  mutate(state = rep(\"New Hampshire\"))\n\nnj_all_words &lt;- nj_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(art.\", \" \"))  %&gt;%\n  mutate(state = rep(\"New Jersey\"))\n\nny_all_words &lt;- ny_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  mutate(state = rep(\"New York\"))\n\nnc_all_words &lt;- nc_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \")) %&gt;%\n  mutate(state = rep(\"North Carolina\"))\n\npa_all_words &lt;- pa_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \")) %&gt;%\n  mutate(state = rep(\"Pennsylvania\"))\n\nri_all_words &lt;- ri_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \")) %&gt;%\n  mutate(state = rep(\"Rhode Island\"))\n\nsc_all_words &lt;- sc_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \"))  %&gt;%\n  mutate(state = rep(\"South Carolina\"))\n\nva_all_words &lt;- va_con_tidy_nostop %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  slice_max(n = 20, order_by = n) %&gt;%\n  filter(!word%in%c(\"(--\", \" \")) %&gt;%\n  mutate(state = rep(\"Virginia\"))\n\n\nthirteen_cons2 &lt;- rbind(ct_all_words,\n                       de_all_words,\n                       ga_all_words,\n                       ma_all_words,\n                       md_all_words,\n                       nc_all_words,\n                       nh_all_words,\n                       nj_all_words,\n                       ny_all_words,\n                       pa_all_words,\n                       ri_all_words,\n                       sc_all_words,\n                       va_all_words)\n\nthirteen_cons2_filtered &lt;- thirteen_cons2 %&gt;%\n  group_by(state) %&gt;%\n  slice_max(n, n = 1) %&gt;%\n  ungroup()\n\nstates &lt;- states()\n\nRetrieving data for the year 2021\n\nall_words_map_data &lt;- thirteen_cons2_filtered %&gt;% \n  left_join(states, by = c(\"state\" = \"NAME\"))\n\nmost_used_map &lt;- ggplot(all_words_map_data, aes(fill = word)) +\n  geom_sf(aes(geometry = geometry)) \n  labs(fill = \"Most Popular Word\")\n\n$fill\n[1] \"Most Popular Word\"\n\nattr(,\"class\")\n[1] \"labels\"\n\nmost_used_map"
  },
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Project 2 - State Constitution Analysis",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "proposal.html#dataset",
    "href": "proposal.html#dataset",
    "title": "Project 2 - State Constitution Analysis",
    "section": "Dataset",
    "text": "Dataset\n\n## read data"
  },
  {
    "objectID": "proposal.html#reason-for-choosing-this-dataset",
    "href": "proposal.html#reason-for-choosing-this-dataset",
    "title": "Project 2 - State Constitution Analysis",
    "section": "Reason for Choosing this Dataset",
    "text": "Reason for Choosing this Dataset\nOur Project: We intend to examine the United States’s individual state constitutions for the frequency of specific keywords and visualize these onto an interactive map of the United States which allows the user to adjust for time, beginning with the 13 colonies and adding more states as time continues and more states are formed."
  },
  {
    "objectID": "proposal.html#questions-and-analysis-plan",
    "href": "proposal.html#questions-and-analysis-plan",
    "title": "Project 2 - State Constitution Analysis",
    "section": "Questions and Analysis Plan",
    "text": "Questions and Analysis Plan\nResearch question: Does the time a state came into being affect the keywords used in its Constitution?"
  },
  {
    "objectID": "proposal.html#in-depth-proposal-and-motivations",
    "href": "proposal.html#in-depth-proposal-and-motivations",
    "title": "Project 2 - State Constitution Analysis",
    "section": "In-depth proposal and motivations:",
    "text": "In-depth proposal and motivations:\nIn order to better understand the political and legal differences within states, especially the differences between the states that were a part of the original thirteen colonies and those who were not, we aim to analyze the constitutions of all fifty US states for certain keywords: “freedom,” “liberty,” “welfare,” “consent,” “prohibit,” “equality,” and “rights.” Once we ascertain the frequency of these keywords within each constitution, we will create seven different maps of the United States (one for each keyword) colored by the frequency of the keyword. This will help us understand the way language is used in different state constitutions. We will then make these maps interactive using the variable of time; we hope to use the time scale to show when different states came into being, starting with the original thirteen colonies. This will help us understand if the time a state was ratified has a large effect on the language used in the constitution."
  },
  {
    "objectID": "proposal.html#weekly-plan-of-attack",
    "href": "proposal.html#weekly-plan-of-attack",
    "title": "Project 2 - State Constitution Analysis",
    "section": "Weekly “plan of attack”",
    "text": "Weekly “plan of attack”\nWeek 1 (April 7th -13th)\n\nEstablish a process to scrape the individual constitutions from state government websites and convert them into tidy data frames, excluding all text from the website not in the constitution (Basil-Anne)\nReplicate this process for all 50 states (Each team member uses the process finalized in the previous step to complete a portion of the states, each person will be responsible for at least 15 states) (Katie, Cassie, Basil-Anne)\nRun analysis on each new dataset using the key words (this will be the same process as the previous step where each team member takes a portion of the states and follows the same procedure) (Katie, Cassie, Basil-Anne)\n\nThis should result in data frames for each state with columns indicating the appearances of each keyword\n\n\nWeek 2 (14th - 20th)\n\nJoin the separate state data frames into one dataframe using the key words (Basil-Anne)\nCreate interactive maps for the 7 key words (each team member will take 2 maps following the same workflow) (Katie, Cassie, Basil-Anne)\nBegin working on Presentation Slides (Katie) and begin write-up (Cassie)\n\nWeek 3 (April 21st - 27th)\n\nFinish presentation slides using the interactive maps (Katie with help from other team members)\nComplete write up of the project (Cassie)\nCreate Website with interactive maps and write up (Katie)"
  },
  {
    "objectID": "proposal.html#project-organization-of-project-repository",
    "href": "proposal.html#project-organization-of-project-repository",
    "title": "Project 2 - State Constitution Analysis",
    "section": "Project organization of project repository",
    "text": "Project organization of project repository\nAs we are creating a website, we will need an index.qmd, a quarto.yml, and an about.qmd. We will have links to all portions of the project (proposal, presentation, write-up, and page with interactive maps) within the website, accessible within a tab; these will also be within the repo in qmd files. Within the repository, these pages are all easily accessible in the code panel; none are within specific folders. We will eventually have a “data” folder with all datasets once they have been located, scraped, and wrangled, as learning the techniques for doing this will be the meat of our project. Aesthetically, the final website will have a tab at the top for accessing other portions of the project, and the interactive maps will either be on the front page or within one of the said tabs. The front page could also be an intro to our project."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "State Constitution Analysis",
    "section": "",
    "text": "Introduction\nIn our project, we aim to understand how the language used in the state constitutions of the original 13 colonies of the United States might explain political or legal differences between the states. To do this, we picked seven keywords that relate both to individual and group political and social freedoms; “freedom,” “liberty,” “welfare,” “consent,” “prohibit,” “equality,” and “rights,” and analyzed each constitution for the frequency of these keywords. We also chose to analyze the top 20 words in each state constitution (minus stop words) regardless of keywords, since as we began our first analysis we realized that not every constitution included every keyword. Most of our text datasets were scraped from the Avalon Project, a database of key historical documents established by Yale Law School. There were three states whose constitutions were not available on the Avalon database: Rhode Island, Virginia, and Connecticut. Rhode Island and Virginia were scraped from Word Service and Connecticut was scraped from the Conneticut General assembly website. After our in-class presentation, we also chose to scrape the text of the federal Constitution and analyze it for both our keywords and the top 20 words in order to provide a better comparison for the language used in constitutions.\nJustification of Approach, Code, and Visualizations:\nWe decided to create a ShinyApp that shows the frequency of our keywords for each state. We decided to make these apps interactive with the variable of time, so the viewer can see when different states ratified their constitutions. This will help us visualize whether or not the year a state ratified its constitution has an effect on the language used within it, and specifically the frequency of our keywords. Many of the states were ratified around 1776, the same year that the Declaration of Independence was signed, but the Federal Constitution was not officially ratified until 1788 and did not take effect until 1789 (its weaker predecessor, the Articles of Confederation, was ratified in 1781), and some states, such as Rhode Island, did not ratify their constitutions until as late as 1843. Thus, time is an important variable to consider when discussing constitutional language, especially considering the fervent debate and frequent changes in how the United States was to be governed in the late eighteenth century.\nOur process began by scraping the data and cleaning it. An example of this process, here applied to the Virginia state constitution, is below:\nIn the next code chunk, we search for our keywords:\nWe also chose to create a frequency histogram for the top 20 words in each state, regardless of whether or not the top 20 contained our chosen keywords. We decided to do so after we analyzed each state’s constitution for our keywords and realized not every state’s constitution contained every keyword, and we wanted to ensure that we still got a good grasp on the most common words used in every constitution. An example of the code for the histogram (and the necessary data wrangling and removing of stop words) can be found below:\nWe also made a map of the most common words across all 13 states. The most common words were “art” (short for article), “council,” “county,” “government,” “house,” “people,” “person,” “sec,” (short for section) and “sect” (also short for section). The code for this map can be seen below:\nDiscussion\nIn our analysis of the state constitutions, we found that much of the language used (as displayed by the top 20 words) was very logistical and administrative in nature; for instance, the top three words in Virginia’s constitution were “house,” “government,” and “people.” These words, and many others like them, are not charged with emotional language or linked to particular political or moral stances; rather, they seek to establish a basic framework for governance. Another popular word among all constitutions was “sec” or “section,” which simply refers to different sections of the document.\nAdditionally, the map of the most common words across all 13 states supports our conclusion that most language used in constitutions is administrative in nature. As explicated above, the most common words were “art,” “council,” “county,” “government,” “house,” “people,” “person,” “sec,” and “sect.” Three of these words (art, sec, and sect) refer to different sections of the document, and the others all refer to either the governing system (council, county, government, house) or those who are governed (people, person).\nOur ShinyApp made comparing the frequency of keywords across states quite easy, and also helped us understand the relatively small amount of mentions all of these keywords had. It also provided a geographical reference for all states, although there did not seem to be a clear link between keyword concentration and geographical location.\nAdding the Federal Constitution to our analysis also helped provide us with a better understanding of the language typically used in constitutions. Much of the language in the federal constitution was still quite administrative or classifying in nature, with the top three words being “United” (likely contained within the phrase “the United States”), “president,” and “congress,” all words that either described the name of the country or important branches of its power. It did, however, include a couple words that had the potential to be slightly more emotionally charged based on context; for instance, “duties” could refer to administrative duties such as time served, but it could also refer to the moral duties that the representatives of a governing body have to their citizens. The word “history” also appeared, which, depending on context, could refer to the tumultuous history the United States had with Britain, or it could refer to the legacy the Founding Fathers wanted to leave for posterity. Overall, however, these words remain relatively administrative in nature.\nWhen reflecting upon our original question- whether the language used in the original constitutions of the 13 colonies can explain political or legal differences between the states- it is relatively clear from our histograms and keyword frequency visualizations that there does not seem to be an obvious link. Much of the language of the constitutions is relatively administrative and logistical, providing a basic framework for government function rather than providing ideological stances. It is imperative to note, however, that we did not include amendments in our analysis (our reasoning was that it would prove beyond the scale of this project to match the language in amendments to the date of the amendments, as some states have dozens of amendments ratified throughout the last two hundred years); it is possible that language in the amendments is more ideological than that of the original constitutions."
  }
]