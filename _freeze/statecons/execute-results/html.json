{
  "hash": "e31585fbe286f8929d075fb5ed55c608",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"State_constitutions\"\nformat: html\neditor: visual\n---\n\n\n## List Of States\n\nConnecticut: <https://www.cga.ct.gov/asp/Content/constitutions/1818Constitution.htm> (Basil-Anne)\n\nDelaware: <https://avalon.law.yale.edu/18th_century/de02.asp> (Basil-Anne)\n\nGeorgia: <https://avalon.law.yale.edu/18th_century/ga02.asp> (Katie)\n\nMaryland: <https://avalon.law.yale.edu/17th_century/ma02.asp> (Katie)\n\nMassachusetts: <http://www.nhinet.org/ccs/docs/ma-1780.htm> (Basil-Anne)\n\nNew Hampshire: <https://avalon.law.yale.edu/18th_century/nh09.asp> (Katie)\n\nNew Jersey: <https://avalon.law.yale.edu/18th_century/nj15.asp> (Katie)\n\nNew York: <https://avalon.law.yale.edu/18th_century/ny01.asp> (Cassie)\n\nNorth Carolina: <https://avalon.law.yale.edu/18th_century/nc07.asp> (Cassie)\n\nPennsylvania: <https://avalon.law.yale.edu/18th_century/pa08.asp> (Cassie)\n\nRhode Island: <https://www.wordservice.org/State%20Constitutions/usa1031.htm> (Basil-Anne)\n\nSouth Carolina: <https://avalon.law.yale.edu/18th_century/sc02.asp> (Cassie)\n\nVirginia: <https://www.wordservice.org/State%20Constitutions/usa1025.htm> (Basil-Anne)\n\n## Connecticut\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'dplyr' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tidytext)\nlibrary(stringr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'stringr' was built under R version 4.2.3\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'ggplot2' was built under R version 4.2.3\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(forcats)\n\nct_url <- \"https://www.cga.ct.gov/asp/Content/constitutions/1818Constitution.htm\"\nct_html <- read_html(ct_url)\n\nct_text <- html_text(ct_html)\n\nct_con <- data.frame(word = unlist(strsplit(ct_text, \"\\\\s+\"))) %>%\n\n  filter(word != \"\")  %>%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\")) %>%\n  filter(!word==\"\")\n\nrows_to_exclude_ct <- c(1:7, 223:298, 6012:12230)\n\nct_con_tidy <- ct_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude_ct))\n\nct_con_join <- ct_con_tidy %>%\n  mutate(state = rep(\"Connecticut\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nct_word_count <- ct_con_tidy %>%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %>%\n  count(word)\n\ndata(\"stop_words\")\nct_con_tidy_nostop <- ct_con_tidy %>%\n anti_join(stop_words) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(word)`\n```\n\n\n:::\n\n```{.r .cell-code}\nct_con_tidy_nostop %>%\n  count(word, sort = TRUE) %>%\n    slice_max(n = 20, order_by = n) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           word   n\n1           sec 100\n2           art  94\n3      assembly  44\n4     governour  36\n5           law  35\n6         house  25\n7        office  25\n8    amendments  23\n9       altered  22\n10        votes  21\n11            4  20\n12     electors  20\n13       manner  20\n14 constitution  19\n15       person  19\n16         time  19\n17            3  18\n18    secretary  18\n19            6  17\n20            2  15\n21         town  15\n```\n\n\n:::\n:::\n\n\n## Delaware\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nde_url <- \"https://avalon.law.yale.edu/18th_century/de02.asp\"\nde_html <- read_html(de_url)\n\nde_text <- html_text(de_html)\n\nde_con <- data.frame(word = unlist(strsplit(de_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  \n\nrows_to_exclude <- c(1:54, 3721:3796)\n\nde_con_tidy <- de_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude))\n\nde_con_join <- de_con_tidy %>%\n  mutate(state = rep(\"Delaware\"))\n```\n:::\n\n\n## Georgia\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nga_url <- \"https://avalon.law.yale.edu/18th_century/ga02.asp\"\nga_html <- read_html(ga_url)\n\nga_text <- html_text(ga_html)\n\nga_con <- data.frame(word = unlist(strsplit(ga_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  \n\nrows_to_exclude_ga <- c(1:56, 4422:4652)\n\nga_con_tidy <- ga_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude_ga))\n\nga_con_join <- ga_con_tidy %>%\n  mutate(state = rep(\"Georgia\"))\n```\n:::\n\n\n## Maryland\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nmd_url <- \"https://avalon.law.yale.edu/17th_century/ma02.asp\"\nmd_html <- read_html(md_url)\n\nmd_text <- html_text(md_html)\n\nmd_con <- data.frame(word = unlist(strsplit(md_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  \n\nrows_to_exclude_md <- c(1:94, 2623:2669, 8854:9084)\n\nmd_con_tidy <- md_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude_md))\n\nmd_con_join <- md_con_tidy %>%\n  mutate(state = rep(\"Maryland\"))\n```\n:::\n\n\n## Massachusetts\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nma_url <- \"http://www.nhinet.org/ccs/docs/ma-1780.htm\"\nma_html <- read_html(ma_url)\n\nma_text <- html_text(ma_html)\n\nma_con <- data.frame(word = unlist(strsplit(ma_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  \n\nrows_to_exclude_ma <- c(11433:11445)\n\nma_con_tidy <- ma_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude_ma))\n\nma_con_join <- ma_con_tidy %>%\n  mutate(state = rep(\"Massachusetts\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'tidyr' was built under R version 4.2.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n✔ readr     2.1.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()         masks stats::filter()\n✖ readr::guess_encoding() masks rvest::guess_encoding()\n✖ dplyr::lag()            masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tidytext)\nma_word_count <- ma_con_tidy %>%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %>%\n  count(word)\n\ndata(\"stop_words\")\nma_con_tidy_nostop <- ma_con_tidy %>%\n anti_join(stop_words) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(word)`\n```\n\n\n:::\n\n```{.r .cell-code}\nma_con_tidy_nostop %>%\n  count(word, sort = TRUE) %>%\n    slice_max(n = 20, order_by = n) %>%\n  filter(!word%in%c(\"(art.\", \"\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              word  n\n1             art. 87\n2             time 51\n3    commonwealth, 38\n4           public 34\n5     commonwealth 33\n6        governor, 32\n7            house 31\n8         governor 30\n9           shall, 27\n10          senate 26\n11           court 25\n12         persons 25\n13          people 23\n14      government 22\n15          person 21\n16 representatives 21\n17            town 21\n18        council, 20\n19           power 20\n20    constitution 19\n21           time, 19\n```\n\n\n:::\n:::\n\n\n## New Hampshire\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nnh_url <- \"https://avalon.law.yale.edu/18th_century/nh09.asp\"\nnh_html <- read_html(nh_url)\n\nnh_text <- html_text(nh_html)\n\nnh_con <- data.frame(word = unlist(strsplit(nh_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  \n\nrows_to_exclude_nh <- c(1:63, 994:1242)\n\nnh_con_tidy <- nh_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude_nh))\n\nnh_con_join <- nh_con_tidy %>%\n  mutate(state = rep(\"New Hampshire\"))\n```\n:::\n\n\n## New Jersey\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nnj_url <- \"https://avalon.law.yale.edu/18th_century/nj15.asp\"\nnj_html <- read_html(nj_url)\n\nnj_text <- html_text(nj_html)\n\nnj_con <- data.frame(word = unlist(strsplit(nj_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  \n\nrows_to_exclude_nj <- c(1:55, 2524:2889)\n\nnj_con_tidy <- nj_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude_nj))\n```\n:::\n\n\n## New York\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nny_url <- \"https://avalon.law.yale.edu/18th_century/ny01.asp\"\nny_html <- read_html(ny_url)\n\nny_text <- html_text(ny_html)\n\nny_con <- data.frame(word = unlist(strsplit(ny_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  \n\nrows_to_exclude <- c(1:68, 7813:8781)\n\nny_con_tidy <- ny_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude))\n\nny_con_join <- ny_con_tidy %>%\n  mutate(state = rep(\"New York\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidytext)\n\nny_word_count <- ny_con_tidy %>%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %>%\n  count(word)\n\ndata(\"stop_words\")\nny_con_tidy_nostop <- ny_con_tidy %>%\n anti_join(stop_words) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(word)`\n```\n\n\n:::\n\n```{.r .cell-code}\nny_con_tidy_nostop %>%\n  count(word, sort = TRUE) %>%\n    slice_max(n = 20, order_by = n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              word  n\n1           people 39\n2           state, 37\n3           county 22\n4        authority 21\n5      legislature 20\n6           shall, 20\n7             time 20\n8         assembly 19\n9              \"he 18\n10      government 18\n11          senate 16\n12      convention 15\n13        further, 14\n14        senators 14\n15             day 13\n16            doth 13\n17            laws 13\n18         ordain, 13\n19          colony 12\n20           court 12\n21      determine, 12\n22          judges 12\n23           power 12\n24 representatives 12\n```\n\n\n:::\n:::\n\n\n## North Carolina\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nnc_url <- \"https://avalon.law.yale.edu/18th_century/nc07.asp\"\nnc_html <- read_html(nc_url)\n\nnc_text <- html_text(nc_html)\n\nnc_con <- data.frame(word = unlist(strsplit(nc_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  \n\nrows_to_exclude <- c(1:58, 3991:4231)\n\nnc_con_tidy <- nc_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude))\n\nnc_con_join <- nc_con_tidy %>%\n  mutate(state = rep(\"North Carolina\"))\n```\n:::\n\n\n## Pennsylvania\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\npa_url <- \"https://avalon.law.yale.edu/18th_century/pa08.asp\"\npa_html <- read_html(pa_url)\n\npa_text <- html_text(pa_html)\n\npa_con <- data.frame(word = unlist(strsplit(pa_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  \n\nrows_to_exclude <- c(1:57, 6196:6533)\n\npa_con_tidy <- pa_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude))\n\npa_con_join <- pa_con_tidy %>%\n  mutate(state = rep(\"Pennsylvania\"))\n```\n:::\n\n\n## Rhode Island\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nri_url <- \"https://www.wordservice.org/State%20Constitutions/usa1031.htm\"\nri_html <- read_html(ri_url)\n\nri_text <- html_text(ri_html)\n\nri_con <- data.frame(word = unlist(strsplit(ri_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  %>%\n  mutate(word = str_replace_all(word, \"[[:punct:][:space:]]+\", \"\"))  %>%\n  filter(!word==\"\")\n\n\nrows_to_exclude_ri <- c(1:200, 7322:7331)\n\nri_con_tidy <- ri_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude_ri))\n\nri_con_join <- ri_con_tidy %>%\n  mutate(state = rep(\"Rhode Island\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidytext)\nri_word_count <- ri_con_tidy %>%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %>%\n  count(word)\n\ndata(\"stop_words\")\nri_con_tidy_nostop <- ri_con_tidy %>%\n anti_join(stop_words) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(word)`\n```\n\n\n:::\n\n```{.r .cell-code}\nri_con_tidy_nostop %>%\n  count(word, sort = TRUE) %>%\n    slice_max(n = 20, order_by = n) %>%\n  filter(!word%in%c(\"(--\", \" \"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              word  n\n1              sec 88\n2         assembly 47\n3              law 38\n4           person 35\n5         election 34\n6             time 34\n7             town 33\n8     constitution 30\n9           office 29\n10            city 28\n11        governor 27\n12           house 26\n13            vote 22\n14         elected 18\n15        officers 18\n16 representatives 17\n17         article 14\n18           court 14\n19        military 14\n20          people 14\n21       secretary 14\n```\n\n\n:::\n:::\n\n\n## South Carolina\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nsc_url <- \"https://avalon.law.yale.edu/18th_century/sc02.asp\"\nsc_html <- read_html(sc_url)\n\nsc_text <- html_text(sc_html)\n\nsc_con <- data.frame(word = unlist(strsplit(sc_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  \n\nrows_to_exclude <- c(1:58, 5639:5880)\n\nsc_con_tidy <- sc_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude))\n\nsc_con_join <- sc_con_tidy %>%\n  mutate(state = rep(\"South Carolina\"))\n```\n:::\n\n\n## Virginia\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nva_url <- \"https://www.wordservice.org/State%20Constitutions/usa1025.htm\"\nva_html <- read_html(va_url)\n\nva_text <- html_text(va_html)\n\nva_con <- data.frame(word = unlist(strsplit(va_text, \"\\\\s+\"))) %>%\n  filter(word != \"\")  \n\nrows_to_exclude_va <- c(1:201, 3680:3689)\n\nva_con_tidy <- va_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude_va))\n\nva_con_join <- va_con_tidy %>%\n  mutate(state = rep(\"Virgina\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidytext)\nva_word_count <- va_con_tidy %>%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %>%\n  count(word)\n\ndata(\"stop_words\")\nva_con_tidy_nostop <- va_con_tidy %>%\n anti_join(stop_words) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(word)`\n```\n\n\n:::\n\n```{.r .cell-code}\nva_con_tidy_nostop %>%\n  count(word, sort = TRUE) %>%\n    slice_max(n = 20, order_by = n) %>%\n  filter(!word%in%c(\"(--\", \" \"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              word  n\n1            house 18\n2             sec. 15\n3           advice  9\n4      government,  9\n5             laws  9\n6        governor,  8\n7            privy  8\n8          appoint  7\n9           county  7\n10      government  7\n11          houses  7\n12           joint  7\n13          people  7\n14 representatives  7\n15        virginia  7\n16        assembly  6\n17          ballot  6\n18          chosen  6\n19         council  6\n20        council,  6\n21        exercise  6\n22            free  6\n23         people,  6\n24           power  6\n25          public  6\n26      respective  6\n27       virginia,  6\n```\n\n\n:::\n:::\n\n\n## Federal\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nfederal_url <- \"https://www.usconstitution.net/const-html/\"\nfederal_html <- read_html(federal_url)\n\nfederal_text <- html_text(federal_html)\n\nfederal_con <- data.frame(word = unlist(strsplit(federal_text, \"\\\\s+\"))) %>%\n  filter(word != \"\" & word != \"-\" & word != \"=\" & !str_detect(word, \"[[:punct:]]\")) %>%\n  mutate(word = str_trim(word))\n\nrows_to_exclude_federal <- c(1:1900, 10012:11573)\n\nfederal_con_tidy <- federal_con %>%\n  mutate(word = tolower(word)) %>%\n  filter(!(row_number() %in% rows_to_exclude_federal))\n\nfederal_con_join <- federal_con_tidy %>%\n  mutate(state = rep(\"Federal\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfederal_word_count <- federal_con_tidy %>%\n  filter(word %in%\n  c(\"freedom\", \"liberty\", \"welfare\", \"consent\", \"prohibit\", \"equality\", \"rights\")) %>%\n  count(word)\n\ndata(\"stop_words\")\nfederal_con_tidy_nostop <- federal_con_tidy %>%\n anti_join(stop_words) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(word)`\n```\n\n\n:::\n\n```{.r .cell-code}\nfederal_con_tidy_nostop %>%\n  count(word, sort = TRUE) %>%\n    slice_max(n = 20, order_by = n) %>%\n  filter(!word%in%c(\"(--\", \" \"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              word  n\n1           united 69\n2        president 65\n3         congress 38\n4        amendment 37\n5         ratified 30\n6           person 29\n7          article 24\n8             vice 22\n9           office 20\n10           power 19\n11        citizens 18\n12             law 18\n13            time 18\n14         section 16\n15          powers 15\n16 representatives 15\n17    constitution 14\n18          duties 14\n19         history 14\n20            note 13\n```\n\n\n:::\n\n```{.r .cell-code}\nfederal_con_tidy_nostop %>%\n  count(word, sort = TRUE) %>%\n  top_n(20) %>%\n  ggplot(aes(y = fct_reorder(word, n), x = n, fill = n)) +\n  geom_col() +\n  guides(fill = FALSE) +\n  labs(y = \"Most Common Words\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSelecting by n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](statecons_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n## 13 colonies data frame and map\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tmap)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nBreaking News: tmap 3.x is retiring. Please test v4, e.g. with\nremotes::install_github('r-tmap/tmap')\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tigris)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n```\n\n\n:::\n\n```{.r .cell-code}\nthirteen_cons <- rbind(ct_con_join,\n                       de_con_join,\n                       ga_con_join,\n                       ma_con_join,\n                       md_con_join,\n                       nc_con_join,\n                       nh_con_join,\n                       ny_con_join,\n                       pa_con_join,\n                       ri_con_join,\n                       sc_con_join,\n                       va_con_join)\n```\n:::\n",
    "supporting": [
      "statecons_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}