url <- "https://www.reed.edu/ir/success.html"
tables <- url %>%
read_html() %>%
html_nodes(css = "table")
grad_table <- html_table(tables[[2]], fill = TRUE)
occupation_table <- html_table(tables[[1]], fill = TRUE)
grad_table
view(grad_table)
grad_data <- grad_table %>%
pivot_longer(c(`MBAs`, `JDs`, 'PhDs', 'MDs' ), names_to = "degree type", values_to = "school")
grad_data
# Hint: Use `parse_number()` within `mutate()` to fix one of the columns
occupation_data <- occupation_table %>%
rename("career_type" = X1, "percent" = X2) %>%
mutate(percent = parse_number(percent))
occupation_data
ggplot(data = occupation_data, aes(career_type, percent, color = career_type, fill = career_type)) +
geom_col()
url2 <- "https://www.reed.edu/ir/gradrateshist.html"
tables <- url2 %>%
read_html() %>%
html_nodes(css = "table")
grad_rates_table <- html_table(tables[[1]], fill = TRUE)
grad_rates_table
ggplot(grad_rates_new, aes(entering_class_year, percent, color=years))+
geom_line(size = 1.5) +
scale_x_continuous(breaks = seq(min(grad_rates_new$entering_class_year),
max(grad_rates_new$entering_class_year), by = 5)) +
scale_color_manual(values = c("deeppink3", "darkorange2", "goldenrod1"))
colnames(grad_rates_table) <- c("entering_class_year", "cohort_size", "graduated_in_4", "graduated_in_5", "graduated_in_6")
grad_rates_table <- filter(grad_rates_table,!row_number()==1)
grad_rates_table
grad_rates_new <- grad_rates_table %>%
pivot_longer(c(graduated_in_4, graduated_in_5, graduated_in_6), names_to = "years", values_to = "percent") %>%
mutate(percent = parse_number(percent))
grad_rates_new
grad_rates_new$entering_class_year <- as.numeric(as.character(grad_rates_new$entering_class_year))
ggplot(grad_rates_new, aes(entering_class_year, percent, color=years))+
geom_line(size = 1.5) +
scale_x_continuous(breaks = seq(min(grad_rates_new$entering_class_year),
max(grad_rates_new$entering_class_year), by = 5)) +
scale_color_manual(values = c("deeppink3", "darkorange2", "goldenrod1"))
colnames(grad_rates_table) <- c("entering_class_year", "cohort_size", "graduated_in_4", "graduated_in_5", "graduated_in_6")
grad_rates_table <- filter(grad_rates_table,!row_number()==1)
grad_rates_table
grad_rates_new <- grad_rates_table %>%
pivot_longer(c(graduated_in_4, graduated_in_5, graduated_in_6), names_to = "years", values_to = "percent") %>%
mutate(percent = parse_number(percent))
grad_rates_new$entering_class_year <- as.numeric(as.character(grad_rates_new$entering_class_year))
ggplot(grad_rates_new, aes(entering_class_year, percent, color=years))+
geom_line(size = 1.5) +
scale_x_continuous(breaks = seq(min(grad_rates_new$entering_class_year),
max(grad_rates_new$entering_class_year), by = 5)) +
scale_color_manual(values = c("deeppink3", "darkorange2", "goldenrod1"))
colnames(grad_rates_table) <- c("entering_class_year", "cohort_size", "graduated_in_4", "graduated_in_5", "graduated_in_6")
grad_rates_table <- filter(grad_rates_table,!row_number()==1)
grad_rates_new <- grad_rates_table %>%
pivot_longer(c(graduated_in_4, graduated_in_5, graduated_in_6), names_to = "years", values_to = "percent") %>%
mutate(percent = parse_number(percent))
grad_rates_new$entering_class_year <- as.numeric(as.character(grad_rates_new$entering_class_year))
ggplot(grad_rates_new, aes(entering_class_year, percent, color=years))+
geom_line(size = 1.5) +
scale_x_continuous(breaks = seq(min(grad_rates_new$entering_class_year),
max(grad_rates_new$entering_class_year), by = 5)) +
scale_color_manual(values = c("deeppink3", "darkorange2", "goldenrod1"))
library(rvest)
library(dplyr)
url <- "https://avalon.law.yale.edu/18th_century/de02.asp"
html <- read_html(url)
text <- html_text(html)
de_con <- data.frame(word = unlist(strsplit(text, "\\s+"))) %>%
filter(word != "")
head(de_con)
View(de_con)
View(de_con)
library(rvest)
library(dplyr)
url <- "https://avalon.law.yale.edu/18th_century/de02.asp"
html <- read_html(url)
text <- html_text(html)
de_con <- data.frame(word = unlist(strsplit(text, "\\s+"))) %>%
filter(word != "")
rows_to_exclude <- c(1:54, 3721:3796)
de_con_tidy <- de_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude))
library(rvest)
library(dplyr)
de_url <- "https://avalon.law.yale.edu/18th_century/de02.asp"
de_html <- read_html(de_url)
de_text <- html_text(de_html)
de_con <- data.frame(word = unlist(strsplit(de_text, "\\s+"))) %>%
filter(word != "")
rows_to_exclude <- c(1:54, 3721:3796)
de_con_tidy <- de_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude))
View(de_con)
shiny::runApp('state_cons_app')
runApp('Downloads')
runApp('state_cons_app')
library(rvest)
library(dplyr)
library(tidyverse)
library(tidytext)
ct_url <- "https://www.cga.ct.gov/asp/Content/constitutions/1818Constitution.htm"
ct_html <- read_html(ct_url)
ct_text <- html_text(ct_html)
ct_con <- data.frame(word = unlist(strsplit(ct_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", "")) %>%
filter(!word== "")
rows_to_exclude_ct <- c(1:7, 223:298, 6012:12230)
ct_con_tidy <- ct_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude_ct))
library(tidyverse)
library(tidytext)
ct_word_count <- ct_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word)
data("stop_words")
ct_con_tidy_nostop <- ct_con_tidy %>%
anti_join(stop_words)
ct_all_words <- ct_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
mutate(state = rep("Connecticut"))
library(rvest)
library(dplyr)
de_url <- "https://avalon.law.yale.edu/18th_century/de02.asp"
de_html <- read_html(de_url)
de_text <- html_text(de_html)
de_con <- data.frame(word = unlist(strsplit(de_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", ""))
rows_to_exclude <- c(1:54, 3721:3796)
de_con_tidy <- de_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude))
library(tidyverse)
library(tidytext)
de_word_count <- de_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("Delaware"))
data("stop_words")
de_con_tidy_nostop <- de_con_tidy %>%
anti_join(stop_words)
de_all_words <- de_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
mutate(state = rep("Delaware"))
library(rvest)
library(dplyr)
ga_url <- "https://avalon.law.yale.edu/18th_century/ga02.asp"
ga_html <- read_html(ga_url)
ga_text <- html_text(ga_html)
ga_con <- data.frame(word = unlist(strsplit(ga_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", ""))
rows_to_exclude_ga <- c(1:56, 4422:4652)
ga_con_tidy <- ga_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude_ga))
library(tidyverse)
library(tidytext)
ga_word_count <- ga_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("Georgia"))
data("stop_words")
ga_con_tidy_nostop <- ga_con_tidy %>%
anti_join(stop_words)
ga_all_words <- ga_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
mutate(state = rep("Georgia"))
library(rvest)
library(dplyr)
md_url <- "https://avalon.law.yale.edu/17th_century/ma02.asp"
md_html <- read_html(md_url)
md_text <- html_text(md_html)
md_con <- data.frame(word = unlist(strsplit(md_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", ""))
rows_to_exclude_md <- c(1:94, 2623:2669, 8854:9084)
md_con_tidy <- md_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude_md))
library(tidyverse)
library(tidytext)
md_word_count <- md_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("Maryland"))
data("stop_words")
md_con_tidy_nostop <- md_con_tidy %>%
anti_join(stop_words)
md_all_words <- md_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
mutate(state = rep("Maryland"))
ma_url <- "http://www.nhinet.org/ccs/docs/ma-1780.htm "
ma_html <- read_html(ma_url)
ma_text <- html_text(ma_html)
ma_con <- data.frame(word = unlist(strsplit(ma_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", ""))
rows_to_exclude_ma <- c(11433:11445)
ma_con_tidy <- ma_con %>%
mutate(word = tolower(word)) %>%
mutate(word=gsub("[[:space:]]", "", word)) %>%
filter(!(row_number() %in% rows_to_exclude_ma))
library(tidyverse)
library(tidytext)
ma_word_count <- ma_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("Massachusetts"))
data("stop_words")
ma_con_tidy_nostop <- ma_con_tidy %>%
anti_join(stop_words)
ma_all_words <- ma_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
filter(!word%in%c("(art.", "")) %>%
mutate(state = rep("Massachusetts"))
library(rvest)
library(dplyr)
nh_url <- "https://avalon.law.yale.edu/18th_century/nh09.asp"
nh_html <- read_html(nh_url)
nh_text <- html_text(nh_html)
nh_con <- data.frame(word = unlist(strsplit(nh_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", ""))
rows_to_exclude_nh <- c(1:63, 994:1242)
nh_con_tidy <- nh_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude_nh))
library(tidyverse)
library(tidytext)
nh_word_count <- nh_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("New Hampshire"))
data("stop_words")
nh_con_tidy_nostop <- nh_con_tidy %>%
anti_join(stop_words)
nh_all_words <- nh_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
filter(!word%in%c("(art.", " ")) %>%
mutate(state = rep("New Hampshire"))
library(rvest)
library(dplyr)
nj_url <- "https://avalon.law.yale.edu/18th_century/nj15.asp"
nj_html <- read_html(nj_url)
nj_text <- html_text(nj_html)
nj_con <- data.frame(word = unlist(strsplit(nj_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", ""))
rows_to_exclude_nj <- c(1:55, 2524:2889)
nj_con_tidy <- nj_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude_nj))
library(tidyverse)
library(tidytext)
nj_word_count <- nj_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("New Jersey"))
data("stop_words")
nj_con_tidy_nostop <- nj_con_tidy %>%
anti_join(stop_words)
nj_all_words <- nj_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
filter(!word%in%c("(art.", " "))  %>%
mutate(state = rep("New Jersey"))
library(rvest)
library(dplyr)
ny_url <- "https://avalon.law.yale.edu/18th_century/ny01.asp"
ny_html <- read_html(ny_url)
ny_text <- html_text(ny_html)
ny_con <- data.frame(word = unlist(strsplit(ny_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", ""))
rows_to_exclude <- c(1:68, 7813:8781)
ny_con_tidy <- ny_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude))
library(tidyverse)
library(tidytext)
ny_word_count <- ny_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("New York"))
data("stop_words")
ny_con_tidy_nostop <- ny_con_tidy %>%
anti_join(stop_words)
ny_all_words <- ny_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
mutate(state = rep("New York"))
library(rvest)
library(dplyr)
nc_url <- "https://avalon.law.yale.edu/18th_century/nc07.asp"
nc_html <- read_html(nc_url)
nc_text <- html_text(nc_html)
nc_con <- data.frame(word = unlist(strsplit(nc_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", ""))
rows_to_exclude <- c(1:58, 3991:4231)
nc_con_tidy <- nc_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude))
library(tidyverse)
library(tidytext)
nc_word_count <- nc_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("North Carolina"))
data("stop_words")
nc_con_tidy_nostop <- nc_con_tidy %>%
anti_join(stop_words)
nc_all_words <- nc_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
filter(!word%in%c("(--", " ")) %>%
mutate(state = rep("North Carolina"))
library(rvest)
library(dplyr)
pa_url <- "https://avalon.law.yale.edu/18th_century/pa08.asp"
pa_html <- read_html(pa_url)
pa_text <- html_text(pa_html)
pa_con <- data.frame(word = unlist(strsplit(pa_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", ""))
rows_to_exclude <- c(1:57, 6196:6533)
pa_con_tidy <- pa_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude))
library(tidyverse)
library(tidytext)
pa_word_count <- pa_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("Pennsylvania"))
data("stop_words")
pa_con_tidy_nostop <- pa_con_tidy %>%
anti_join(stop_words)
pa_all_words <- pa_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
filter(!word%in%c("(--", " ")) %>%
mutate(state = rep("Pennsylvania"))
ri_url <- "https://www.wordservice.org/State%20Constitutions/usa1031.htm"
ri_html <- read_html(ri_url)
ri_text <- html_text(ri_html)
ri_con <- data.frame(word = unlist(strsplit(ri_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", "")) %>%
filter(!word== "")
rows_to_exclude_ri <- c(1:200, 7322:7331)
ri_con_tidy <- ri_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude_ri))
library(tidyverse)
library(tidytext)
ri_word_count <- ri_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("Rhode Island"))
data("stop_words")
ri_con_tidy_nostop <- ri_con_tidy %>%
anti_join(stop_words)
ri_all_words <- ri_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
filter(!word%in%c("(--", " ")) %>%
mutate(state = rep("Rhode Island"))
library(rvest)
library(dplyr)
sc_url <- "https://avalon.law.yale.edu/18th_century/sc02.asp"
sc_html <- read_html(sc_url)
sc_text <- html_text(sc_html)
sc_con <- data.frame(word = unlist(strsplit(sc_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", ""))
rows_to_exclude <- c(1:58, 5639:5880)
sc_con_tidy <- sc_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude))
library(tidyverse)
library(tidytext)
sc_word_count <- sc_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("South Carolina"))
data("stop_words")
sc_con_tidy_nostop <- sc_con_tidy %>%
anti_join(stop_words)
sc_all_words <- sc_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
filter(!word%in%c("(--", " "))  %>%
mutate(state = rep("South Carolina"))
va_url <- "https://www.wordservice.org/State%20Constitutions/usa1025.htm"
va_html <- read_html(va_url)
va_text <- html_text(va_html)
va_con <- data.frame(word = unlist(strsplit(va_text, "\\s+"))) %>%
filter(word != "")  %>%
mutate(word = str_replace_all(word, "[[:punct:][:space:]]+", ""))
rows_to_exclude_va <- c(1:201, 3680:3689)
va_con_tidy <- va_con %>%
mutate(word = tolower(word)) %>%
filter(!(row_number() %in% rows_to_exclude_va))
library(tidyverse)
library(tidytext)
va_word_count <- va_con_tidy %>%
filter(word %in%
c("freedom", "liberty", "welfare", "consent", "prohibit", "equality", "rights")) %>%
count(word) %>%
mutate(state = rep("Virginia"))
data("stop_words")
va_con_tidy_nostop <- va_con_tidy %>%
anti_join(stop_words)
va_all_words <- va_con_tidy_nostop %>%
count(word, sort = TRUE) %>%
slice_max(n = 20, order_by = n) %>%
filter(!word%in%c("(--", " ")) %>%
mutate(state = rep("Virginia"))
ct_word_count <- ct_word_count %>%
mutate(state = rep("Connecticut"))
de_word_count <- de_word_count %>%
mutate(state = rep("Delaware"))
ga_word_count <- ga_word_count %>%
mutate(state = rep("Georgia"))
ma_word_count <- ma_word_count %>%
mutate(state = rep("Massachusetts"))
md_word_count <- md_word_count %>%
mutate(state = rep("Maryland"))
nc_word_count <- nc_word_count %>%
mutate(state = rep("North Carolina"))
nh_word_count <- nh_word_count %>%
mutate(state = rep("New Hampshire"))
nj_word_count <- nj_word_count %>%
mutate(state = rep("New Jersey"))
ny_word_count <- ny_word_count %>%
mutate(state = rep("New York"))
pa_word_count <- pa_word_count %>%
mutate(state = rep("Pennsylvania"))
ri_word_count <- ri_word_count %>%
mutate(state = rep("Rhode Island"))
sc_word_count <- sc_word_count %>%
mutate(state = rep("South Carolina"))
va_word_count <- va_word_count %>%
mutate(state = rep("Virginia"))
View(ri_word_count)
View(ct_word_count)
View(de_word_count)
View(ga_word_count)
runApp('state_cons_app')
runApp('state_cons_app')
runApp('state_cons_app/stateconsapp.R')
View(sc_word_count)
View(va_word_count)
thirteen_cons <- bind_rows(ct_word_count,
de_word_count,
ga_word_count,
ma_word_count,
md_word_count,
nc_word_count,
nh_word_count,
nj_word_count,
ny_word_count,
pa_word_count,
ri_word_count,
sc_word_count,
va_word_count)
va_word_count
thirteen_cons <- bind_rows(ct_word_count,
de_word_count,
ga_word_count,
ma_word_count,
md_word_count,
nc_word_count,
nh_word_count,
nj_word_count,
ny_word_count,
pa_word_count,
ri_word_count,
sc_word_count,
va_word_count)
View(thirteen_cons)
runApp('state_cons_app/stateconsapp.R')
runApp('Documents/project-02-state_constitution/stateconsapp.R')
runApp('Documents/project-02-state_constitution/stateconsapp.R')
runApp('Documents/project-02-state_constitution/stateconsapp.R')
